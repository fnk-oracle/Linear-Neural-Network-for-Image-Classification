# -*- coding: utf-8 -*-
"""Linear NN for Images.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jxgHkt9RB3R4WHNbEBgrj_sKF2qCgZfK
"""

import tensorflow as tf

IMG_HEIGHT = 224
IMG_WIDTH = 224
IMG_CHANNELS = 3

CLASS_NAMES = ["daisy", "dandelion", "roses", "sunflowers", "tulips"]

def read_and_decode(filename, resize_dims):
  #1. Read the raw files
  img_bytes = tf.io.read_file(filename) # loads img in jpeg format
  #2. Decode image data
  img = tf.image.decode_jpeg(img_bytes, channels=IMG_CHANNELS) # converts img to pixel values between 0-255
  #3. Convert pixel values to floats in [0, 1]
  img = tf.image.convert_image_dtype(img, tf.float32)
  #4. Resize the image to match desired dimensions
  img = tf.image.resize(img, resize_dims)
  return img

def parse_csvline(csv_line):
  # record_defaults specify the data types for each column
  record_default = ["", ""]
  filename, label_string = tf.io.decode_csv(csv_line, record_default) # will fetch the img name and img label(1 of 5 classes; 0,1,2,3,4)

  #Load the image
  img = read_and_decode(filename, [IMG_HEIGHT, IMG_WIDTH])

  #Convert label string to integer based on the CLASS_NAME index
  label = tf.argmax(tf.math.equal(CLASS_NAMES, label_string, )) #map the class name to label string
  return img, label # returning the img and the corresponding label

# Training dataset
train_dataset = (
    tf.data.TextLineDataset("gs://cloud-ml-data/img/flower_photos/train_set.csv")
    .map(parse_csvline)
    .batch(16) # makes a batch of 16 images
)

eval_dataset = (
    tf.data.TextLineDataset("gs://cloud-ml-data/img/flower_photos/eval_set.csv")
    .map(parse_csvline)
    .batch(16) # batch is called a hyperparameter
)

"""Create a batch dataset of images"""

for image_batch, label_batch in train_dataset.take(13):
  print("Image batch shape: ", image_batch.shape)
  print("Label batch shape: ", label_batch.shape)
  print("Labels: ", label_batch.numpy())

"""Using matplotlib to visualize the picture of a sample datapoint"""

import matplotlib.pyplot as plt

for image_batch, babel_batch in train_dataset.take(6):
  #Take the first image from the batch
  first_image = image_batch[0]
  first_label = label_batch[0]

  # Convert tesnor to numpy array
  plt.imshow(first_image.numpy())
  plt.title(f"Label: {CLASS_NAMES[first_label]}")
  plt.axis('off')
  plt.show()

#Take 1 batch from the dataset
for image_batch, label_batch in train_dataset.take(1):
  fig, axis = plt.subplots(4, 4, figsize=(10, 10)) # Create a 4*4 grid

  for i in range(16): # iterate over first 16 images
    ax = axis[i // 4, i % 4] # determine the grid position
    ax.imshow(image_batch[i].numpy()) # convert tensor to numpy array
    ax.set_title(f"LABEL: {CLASS_NAMES[label_batch[i]]}") # set the title of the image
    ax.axis('off')

  plt.tight_layout()
  plt.show()

"""*Using Linear Functions we will build NN, No activation function, No Convolution*

1. Flatten: 244x244x3 pixel image to a single column, one flaatened vector. RGB will be fllatened
2. Dense Fully Connected Layer:Will be connected to out
3. At the output we will use softmax
"""

# SO dim of input layer of neural network will be 244x244x3 = 150528x1 also called as hidden layer
#Every single node R, G, B in input/hidden layer will be connected to output layer ie 5 nodes of classes
#Output can be random number which will be converted to probability. Sum of all equla to 1
# Y = softmax (B + W * X)
# X - is our flattened image data
# W - trainable weight matrix
# B - is a bias term
# Y - is the output vector of 5 scores

from tensorflow import keras
from tensorflow.keras import models, layers

model = keras.Sequential([
    layers.Flatten(input_shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)),
    layers.Dense(len(CLASS_NAMES), activation='softmax')
])

model.compile(
    optimizer='adam',
    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False),
    metrics=['accuracy']
)

from re import VERBOSE
epochs = 2

history = model.fit(
    train_dataset,
    validation_data=eval_dataset,
    epochs=epochs,
)

import matplotlib.pyplot as plt

plt.plot(history.history["loss"], label="Training Loss")
plt.plot(history.history["val_loss"], label="Validation Loss")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.legend()
plt.show()

plt.plot(history.history["accuracy"], label="Training Accuracy")
plt.plot(history.history["val_accuracy"], label="Validation Accuracy")
plt.xlabel("Epoch")
plt.ylabel("Accuracy")
plt.legend()
plt.show()

import numpy as np
import matplotlib.pyplot as plt
import math

# Take exactly one batch from the evaluation dataset
for images, labels in eval_dataset.take(1):
    # Get model predictions for this batch
    batch_predictions = model.predict(images)
    predicted_indices = np.argmax(batch_predictions, axis=1)

    # Number of images in this batch
    num_images = images.shape[0]

    # Configure how many images to display per row
    num_cols = 4
    num_rows = math.ceil(num_images / num_cols)

    # Create a figure with a suitable size
    plt.figure(figsize=(12, 3 * num_rows))

    for i in range(num_images):
        plt.subplot(num_rows, num_cols, i + 1)

        # Display the image
        plt.imshow(images[i].numpy())
        plt.axis('off')

        # Get predicted and actual class names
        pred_class = CLASS_NAMES[predicted_indices[i]]
        actual_class = CLASS_NAMES[labels[i].numpy()]

        # Show both predicted and actual labels as title
        plt.title(f"Pred: {pred_class}\nActual: {actual_class}", fontsize=10)

    # Adjust spacing to avoid overlapping titles, etc.
    plt.tight_layout()
    plt.show()

